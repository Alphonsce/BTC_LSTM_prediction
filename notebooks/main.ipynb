{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/\n",
    "\n",
    "**Все остальные фичи тоже можно юзать в лстм - модель так будет вообще лютой**\n",
    "- пока делаю: X - это последовательность только close, y - последовательность close\n",
    "- потом: X - это последовательность (close, max, min, volume, еще какая-то статистика для этого момента), y - последовательность close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/btc-4h.csv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    path\n",
    ")\n",
    "\n",
    "df = df[[\"time\", \"close\"]]\n",
    "# df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "\n",
    "df = df[[\"close\"]].values.astype('float32')    # пока для начала - предсказываем последовательность \n",
    "                    # close, основываясь на последовательности close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(df))\n",
    "\n",
    "test_size = len(df) - train_size\n",
    "train, test = df[:train_size], df[train_size:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Фича для одного объекта из датасета - это последовательность из w штук в предыдущие w моменты времени цен**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, lookback):\n",
    "    \"\"\"\n",
    "    Transform a time series into a prediction dataset. We predict lookback steps forward based on lookback steps before.\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - lookback):\n",
    "        feature = dataset[i:i + lookback]\n",
    "        target = dataset[i + 1:i + lookback + 1]\n",
    "        X.append(feature)\n",
    "        y.append(target)    \n",
    "    # return torch.tensor(np.vstack(X)), torch.tensor(np.vstack(y))\n",
    "    return torch.tensor(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3061, 5, 1]) torch.Size([3061, 5, 1])\n",
      "torch.Size([1309, 5, 1]) torch.Size([1309, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "lookback = 5\n",
    "\n",
    "X_train, y_train = create_dataset(train, lookback=lookback)\n",
    "X_test, y_test = create_dataset(test, lookback=lookback)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[48828.1719],\n",
       "         [48944.2305],\n",
       "         [48501.8711],\n",
       "         [49180.9805],\n",
       "         [48978.6797]],\n",
       "\n",
       "        [[48944.2305],\n",
       "         [48501.8711],\n",
       "         [49180.9805],\n",
       "         [48978.6797],\n",
       "         [48821.8711]],\n",
       "\n",
       "        [[48501.8711],\n",
       "         [49180.9805],\n",
       "         [48978.6797],\n",
       "         [48821.8711],\n",
       "         [48790.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[18885.3496],\n",
       "         [18846.6191],\n",
       "         [18876.3691],\n",
       "         [18824.2500],\n",
       "         [18920.9492]],\n",
       "\n",
       "        [[18846.6191],\n",
       "         [18876.3691],\n",
       "         [18824.2500],\n",
       "         [18920.9492],\n",
       "         [19261.1895]],\n",
       "\n",
       "        [[18876.3691],\n",
       "         [18824.2500],\n",
       "         [18920.9492],\n",
       "         [19261.1895],\n",
       "         [19362.0098]]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_3_6_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
